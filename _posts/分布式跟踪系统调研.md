---
title: 分布式跟踪系统调研
date: 2016-11-07 09:21:20
categories: 分布式
tags: 跟踪系统
---
# 需求
分布式系统为什么需要 Tracing
电商平台由数以百计的分布式服务构成，每一个请求路由过来后，会经过多个业务系统并留下足迹，并产生对各种Cache或DB的访问，
但是这些分散的数据对于问题排查，或是流程优化都帮助有限。对于这么一个跨进程/跨线程的场景，汇总收集并分析海量日志就显得
尤为重要。要能做到追踪每个请求的完整调用链路，收集调用链路上每个服务的性能数据，计算性能数据和比对性能指标（SLA），
甚至在更远的未来能够再反馈到服务治理中，那么这就是分布式跟踪的目标了。在业界，twitter 的 zipkin 和淘宝的鹰眼就是类似
的系统，它们都起源于 **Google Dapper** 论文，就像历史上 Hadoop 发源于 Google Map/Reduce 论文，HBase 源自 Google
BigTable 论文一样。

<!--more-->
# 介绍
把分布式系统中各个组件的工作汇总起来，就可以得到一个全面的跟踪系统
Google的Dapper，Twitter的zipkin，淘宝的鹰眼，新浪的Watchman，京东的Hydra，唯品会的Microscope，窝窝网的Tracing
eBay叫Centralized Activity Logging (CAL)，大众点评网叫CAT

# 核心思想
链路监控的核心是：用一个全局的 ID 将分布式请求串接起来，在JVM内部通过ThreadLocal传递，在跨JVM调用的时候，通过中间件（http header, framework）将全局ID传递出去，这样就可以将分布式调用串联起来

# 应用场景
一个下单请求经历了什么？**调用栈**
订单查询的平均QPS,最高QPS,波动情况，**监控QPS**
为什么这个请求很慢，哪个环节出了问题，**监控潜在因素**
数据库的请求量突然上涨，如何排除来源，**链路分析**
这个操作需要依赖哪些东西，是数据库还是消息队列，如果某个redis挂了，哪些业务会受到影响，**依赖分析**

# 架构
![鹰眼架构](http://ww3.sinaimg.cn/mw690/69045600gw1f93cx2ehufj20xe0kwnbz.jpg)
处理过程包括应用内部埋点，日志数据收集，在线和离线的数据分析，结果的存储和展示
## 设计目标
低侵入性——作为非业务组件，应当尽可能少侵入或者无侵入其他业务系统，对于使用方透明，减少开发人员的负担
灵活的应用策略——可以（最好随时）决定所收集数据的范围和粒度
时效性——从数据的收集和产生，到数据计算和处理，再到最终展现，都要求尽可能快
决策支持——这些数据是否能在决策支持层面发挥作用，特别是从 DevOps 的角度
可视化才是王道

如果没有对 RPC 调用框架做统一封装，就可能侵入到每一个业务工程里去写埋点日志


## 埋点
**中间件埋点**、**字节码增强**技术埋点，类似Btrace，最终的目标其实都是一样的：对应用程序透明即可

论文中提到过采样的问题，考虑到数据量很大的时候，全量跟踪会导致很大的压力，采样便应用而生。淘宝用的是hash采样，
京东用的是固定时间段内固定跟踪数量的采样，Dapper使用的是自适应采样，业务量不大可以先全量

还有 [ostrich](https://github.com/twitter/ostrich) 用于定义监控指标（count, gauge, histogram, timer）。用户的在线数量，系统的线程数量

不能造成性能负担：一个价值未被验证，却会影响性能的东西，是很难推广的
因为要写log，业务QPS越高，性能影响越重。通过采样和异步log解决
```
type Span struct {
    TraceID    int64
    Name       string
    ID         int64
    ParentID   int64
    Annotation []Annotation
    Debug      bool
}
```
Span代表某个特定的方法调用，有一个名称和一个id。由一系列的标注组成
```
type Annotation struct {
    Timestamp int64
    Value     string
    Host      Endpoint
    Duration  int32
}
```
Trace是关联到同一个请求的一系列的Span。

## 收集
每个机器上有一个deamon做日志收集。业务进程把自己的Trace发到daemon。
daemon把收集Trace往上一级发送。
多级的collector，类似pub/sub架构。可以负载均衡。
对聚合的数据进行实时分析和离线存储。
离线分析需要将同一条调用链的日志汇总在一起

## 分析
调用链跟踪：把同一TraceID的Span收集起来，按时间排序就是timeline。把ParentID串起来就是调用栈。
抛异常或者超时，在日志里打印TraceID。利用TraceID查询调用链情况，定位问题。
依赖度量：
强依赖：调用失败会直接中断主流程
高度依赖：一次链路中调用某个依赖的几率高
频繁依赖：一次链路调用同一个依赖的次数多
离线分析按TraceID汇总，通过Span的ID和ParentID还原调用关系，分析链路形态。
实时分析对单条日志直接分析，不做汇总，重组。得到当前QPS，延迟
![链路分析](http://ww1.sinaimg.cn/mw690/69045600gw1f93d3aedljj20sg0lcgrl.jpg)

## 数据来源
请求调用链
系统、业务 metrics（CPU, IO, memory，disk, http, servlet, db, cache, jvm...）
异常堆栈
GC log


## 存储
淘宝用[disruptor](https://github.com/LMAX-Exchange/disruptor)实现了一个类似这样的日志组件
eBay和点评的都是用Java并发库中的LBQ来做存储的，队列做存储的好处很明显，就是读写很方便，性能也高
基于disruptor做一个内存队列。当然，这仅仅是当前的方案，如果将来队列无法支持，那么log4j2 将是我们的备选方案
flume作为分布式日志的收集框架
Storm作为分布式流式处理框架
SEDA架构，多阶段事件驱动架构，用disruptor做线程之间的数据交换。将整个处理流程抽象为：验证、分析、告警、存储
存储：将数据全量存储到Hbase
Twitter使用scirbe来把所有的跟踪数据传输到zipkin的后端和hadoop文件系统
数据保留两个星期

## 可视化
必须能读才有价值
zipkin是整套的解决方案

## 监控什么
在线服务，离线服务，批处理任务
### 在线服务
在线服务是指那些需要立即响应的系统，比如，大部分的数据库和HTTP请求都属于这一类。
监控这类系统关键的指标是，执行请求数，错误数，以及延迟。记录正在处理中的请求数量也很有意义。
对请求进行计数时，开始和结束都要记录。结束的时候，可以记录下error和延迟情况

### 离线服务
离线处理并不需要马上响应请求，而且通常都是批量处理的。处理过程可能还分多个阶段。
对于每个阶段，记录来了多少请求，有多少是正在处理中，处理完时要记录下完成时间，以及发送出去了多少响应。如果是批处理的，
还要记录下每一批请求的进入和离开。知道处理完某任务的最后时间对于检测系统是否卡住了非常有用，但是这些信息还是有一定的局限。
更好的方法是，系统定时地发心跳信息，带上时间戳。作业在经历每个阶段都导出最近心跳的时间戳，这样就可以知道一个作业从进入
系统到完成离开所经历的每个阶段的具体耗时。

### 批处理任务
批处理和离线之间的界限很模糊，因为离线处理任务一般也是批处理的。辨别批处理任务的方法是看，它是不是连续不断地运行的，
这个特征使得拆分它们很不容易。监控批处理任务的关键指标是记录最后完成的时间。记下每个主要阶段花费的时间也很有用。
这些应该以推的形式收集。有时候一些特定任务的统计也值得关注，比如处理的记录的总数。对于那些需要运行几分钟以上才完成的作业，
基于周期性拉取的方式监控也很好。这样可以收集到随时间变化的一些数据，比如资源占用以及延迟情况，如果发现任务运行变慢，
这些信息对调试会有帮助。对于运行比较频繁（15分钟内就会运行一次）的批处理任务，可以考虑将它们做成daemon并作为离线服务处理



